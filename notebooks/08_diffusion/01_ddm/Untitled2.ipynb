{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75193d-87d0-46be-84c3-6696962b4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Keras base class for convolution layers.\"\"\"\n",
    "\n",
    "from keras import activations\n",
    "from keras import constraints\n",
    "from keras import initializers\n",
    "from keras import ops\n",
    "from keras import regularizers\n",
    "from keras.backend import standardize_data_format\n",
    "from keras.layers.input_spec import InputSpec\n",
    "from keras.layers.layer import Layer\n",
    "from keras.ops.operation_utils import compute_conv_output_shape\n",
    "from keras.utils.argument_validation import standardize_padding\n",
    "from keras.utils.argument_validation import standardize_tuple\n",
    "\n",
    "\n",
    "class BaseConv(Layer):\n",
    "    \"\"\"Abstract N-D convolution layer (private, used as implementation base).\n",
    "\n",
    "    This layer creates a convolution kernel that is convolved (actually\n",
    "    cross-correlated) with the layer input to produce a tensor of outputs. If\n",
    "    `use_bias` is True (and a `bias_initializer` is provided), a bias vector is\n",
    "    created and added to the outputs. Finally, if `activation` is not `None`, it\n",
    "    is applied to the outputs as well.\n",
    "\n",
    "    Note: layer attributes cannot be modified after the layer has been called\n",
    "    once (except the `trainable` attribute).\n",
    "\n",
    "    Args:\n",
    "        rank: int, the rank of the convolution, e.g. 2 for 2D convolution.\n",
    "        filters: int, the dimension of the output space (the number of filters\n",
    "            in the convolution).\n",
    "        kernel_size: int or tuple/list of `rank` integers, specifying the size\n",
    "            of the convolution window.\n",
    "        strides: int or tuple/list of `rank` integers, specifying the stride\n",
    "            length of the convolution. If only one int is specified, the same\n",
    "            stride size will be used for all dimensions. `strides > 1` is\n",
    "            incompatible with `dilation_rate > 1`.\n",
    "        padding: string, either `\"valid\"` or `\"same\"` (case-insensitive).\n",
    "            `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n",
    "            the left/right or up/down of the input such that output has the same\n",
    "            height/width dimension as the input.\n",
    "        data_format: string, either `\"channels_last\"` or `\"channels_first\"`.\n",
    "            The ordering of the dimensions in the inputs. `\"channels_last\"`\n",
    "            corresponds to inputs with shape `(batch, steps, features)`\n",
    "            while `\"channels_first\"` corresponds to inputs with shape\n",
    "            `(batch, features, steps)`. It defaults to the `image_data_format`\n",
    "            value found in your Keras config file at `~/.keras/keras.json`.\n",
    "            If you never set it, then it will be `\"channels_last\"`.\n",
    "        dilation_rate: int or tuple/list of `rank` integers, specifying the\n",
    "            dilation rate to use for dilated convolution. If only one int is\n",
    "            specified, the same dilation rate will be used for all dimensions.\n",
    "        groups: A positive int specifying the number of groups in which the\n",
    "            input is split along the channel axis. Each group is convolved\n",
    "            separately with `filters // groups` filters. The output is the\n",
    "            concatenation of all the `groups` results along the channel axis.\n",
    "            Input channels and `filters` must both be divisible by `groups`.\n",
    "        activation: Activation function. If `None`, no activation is applied.\n",
    "        use_bias: bool, if `True`, bias will be added to the output.\n",
    "        kernel_initializer: Initializer for the convolution kernel. If `None`,\n",
    "            the default initializer (`\"glorot_uniform\"`) will be used.\n",
    "        bias_initializer: Initializer for the bias vector. If `None`, the\n",
    "            default initializer (`\"zeros\"`) will be used.\n",
    "        kernel_regularizer: Optional regularizer for the convolution kernel.\n",
    "        bias_regularizer: Optional regularizer for the bias vector.\n",
    "        activity_regularizer: Optional regularizer function for the output.\n",
    "        kernel_constraint: Optional projection function to be applied to the\n",
    "            kernel after being updated by an `Optimizer` (e.g. used to implement\n",
    "            norm constraints or value constraints for layer weights). The\n",
    "            function must take as input the unprojected variable and must return\n",
    "            the projected variable (which must have the same shape). Constraints\n",
    "            are not safe to use when doing asynchronous distributed training.\n",
    "        bias_constraint: Optional projection function to be applied to the\n",
    "            bias after being updated by an `Optimizer`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        rank,\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=1,\n",
    "        padding=\"valid\",\n",
    "        data_format=None,\n",
    "        dilation_rate=1,\n",
    "        groups=1,\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"zeros\",\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        trainable=True,\n",
    "        name=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            trainable=trainable,\n",
    "            name=name,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.rank = rank\n",
    "        self.filters = filters\n",
    "        self.groups = groups or 1\n",
    "        self.kernel_size = standardize_tuple(kernel_size, rank, \"kernel_size\")\n",
    "        self.strides = standardize_tuple(strides, rank, \"strides\")\n",
    "        self.dilation_rate = standardize_tuple(\n",
    "            dilation_rate, rank, \"dilation_rate\"\n",
    "        )\n",
    "        self.padding = standardize_padding(padding, allow_causal=rank == 1)\n",
    "        self.data_format = standardize_data_format(data_format)\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.input_spec = InputSpec(min_ndim=self.rank + 2)\n",
    "        self.data_format = self.data_format\n",
    "\n",
    "        if self.filters is not None and self.filters <= 0:\n",
    "            raise ValueError(\n",
    "                \"Invalid value for argument `filters`. Expected a strictly \"\n",
    "                f\"positive value. Received filters={self.filters}.\"\n",
    "            )\n",
    "\n",
    "        if self.filters is not None and self.filters % self.groups != 0:\n",
    "            raise ValueError(\n",
    "                \"The number of filters must be evenly divisible by the \"\n",
    "                f\"number of groups. Received: groups={self.groups}, \"\n",
    "                f\"filters={self.filters}.\"\n",
    "            )\n",
    "\n",
    "        if not all(self.kernel_size):\n",
    "            raise ValueError(\n",
    "                \"The argument `kernel_size` cannot contain 0. Received \"\n",
    "                f\"kernel_size={self.kernel_size}.\"\n",
    "            )\n",
    "\n",
    "        if not all(self.strides):\n",
    "            raise ValueError(\n",
    "                \"The argument `strides` cannot contains 0. Received \"\n",
    "                f\"strides={self.strides}\"\n",
    "            )\n",
    "\n",
    "        if max(self.strides) > 1 and max(self.dilation_rate) > 1:\n",
    "            raise ValueError(\n",
    "                \"`strides > 1` not supported in conjunction with \"\n",
    "                f\"`dilation_rate > 1`. Received: strides={self.strides} and \"\n",
    "                f\"dilation_rate={self.dilation_rate}\"\n",
    "            )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            channel_axis = -1\n",
    "            input_channel = input_shape[-1]\n",
    "        else:\n",
    "            channel_axis = 1\n",
    "            input_channel = input_shape[1]\n",
    "        self.input_spec = InputSpec(\n",
    "            min_ndim=self.rank + 2, axes={channel_axis: input_channel}\n",
    "        )\n",
    "        if input_channel % self.groups != 0:\n",
    "            raise ValueError(\n",
    "                \"The number of input channels must be evenly divisible by \"\n",
    "                f\"the number of groups. Received groups={self.groups}, but the \"\n",
    "                f\"input has {input_channel} channels (full input shape is \"\n",
    "                f\"{input_shape}).\"\n",
    "            )\n",
    "        kernel_shape = self.kernel_size + (\n",
    "            input_channel // self.groups,\n",
    "            self.filters,\n",
    "        )\n",
    "\n",
    "        # compute_output_shape contains some validation logic for the input\n",
    "        # shape, and make sure the output shape has all positive dimensions.\n",
    "        self.compute_output_shape(input_shape)\n",
    "\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\",\n",
    "            shape=kernel_shape,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype,\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                name=\"bias\",\n",
    "                shape=(self.filters,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                trainable=True,\n",
    "                dtype=self.dtype,\n",
    "            )\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.built = True\n",
    "\n",
    "    def convolution_op(self, inputs, kernel):\n",
    "        return ops.conv(\n",
    "            inputs,\n",
    "            kernel,\n",
    "            strides=list(self.strides),\n",
    "            padding=self.padding,\n",
    "            dilation_rate=self.dilation_rate,\n",
    "            data_format=self.data_format,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.convolution_op(\n",
    "            inputs,\n",
    "            self.kernel,\n",
    "        )\n",
    "        if self.use_bias:\n",
    "            if self.data_format == \"channels_last\":\n",
    "                bias_shape = (1,) * (self.rank + 1) + (self.filters,)\n",
    "            else:\n",
    "                bias_shape = (1, self.filters) + (1,) * self.rank\n",
    "            bias = ops.reshape(self.bias, bias_shape)\n",
    "            outputs += bias\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return compute_conv_output_shape(\n",
    "            input_shape,\n",
    "            self.filters,\n",
    "            self.kernel_size,\n",
    "            strides=self.strides,\n",
    "            padding=self.padding,\n",
    "            data_format=self.data_format,\n",
    "            dilation_rate=self.dilation_rate,\n",
    "        )\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"filters\": self.filters,\n",
    "                \"kernel_size\": self.kernel_size,\n",
    "                \"strides\": self.strides,\n",
    "                \"padding\": self.padding,\n",
    "                \"data_format\": self.data_format,\n",
    "                \"dilation_rate\": self.dilation_rate,\n",
    "                \"groups\": self.groups,\n",
    "                \"activation\": activations.serialize(self.activation),\n",
    "                \"use_bias\": self.use_bias,\n",
    "                \"kernel_initializer\": initializers.serialize(\n",
    "                    self.kernel_initializer\n",
    "                ),\n",
    "                \"bias_initializer\": initializers.serialize(\n",
    "                    self.bias_initializer\n",
    "                ),\n",
    "                \"kernel_regularizer\": regularizers.serialize(\n",
    "                    self.kernel_regularizer\n",
    "                ),\n",
    "                \"bias_regularizer\": regularizers.serialize(\n",
    "                    self.bias_regularizer\n",
    "                ),\n",
    "                \"activity_regularizer\": regularizers.serialize(\n",
    "                    self.activity_regularizer\n",
    "                ),\n",
    "                \"kernel_constraint\": constraints.serialize(\n",
    "                    self.kernel_constraint\n",
    "                ),\n",
    "                \"bias_constraint\": constraints.serialize(self.bias_constraint),\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
